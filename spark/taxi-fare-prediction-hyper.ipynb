{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c89f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ef5549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/20 20:56:44 WARN Utils: Your hostname, gim-yelin-ui-iMac.local resolves to a loopback address: 127.0.0.1; using 192.168.219.101 instead (on interface en1)\n",
      "22/05/20 20:56:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/20 20:56:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "MAX_MEMORY=\"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediciton\")\\\n",
    "                .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "                .config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a308b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/yello-ow/taxi/spark/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193f3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.parquet(f\"{data_dir}/train/\")\n",
    "test_df = spark.read.parquet(f\"{data_dir}/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f7037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝을 위한 data \n",
    "toy_df = train_df.sample(False, 0.1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1499b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfbf96",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b197ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "cat_feats = [\n",
    "    \"pickup_location_id\",\n",
    "    \"dropoff_location_id\",\n",
    "    \"day_of_week\"\n",
    "]\n",
    "\n",
    "stages = []\n",
    "\n",
    "for c in cat_feats:\n",
    "    cat_indexer = StringIndexer(inputCol=c, outputCol= c + \"_idx\").setHandleInvalid(\"keep\")\n",
    "    onehot_encoder = OneHotEncoder(inputCols=[cat_indexer.getOutputCol()], outputCols=[c + \"_onehot\"])\n",
    "    stages += [cat_indexer, onehot_encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d1a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "num_feats = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"pickup_time\"\n",
    "]\n",
    "\n",
    "for n in num_feats:\n",
    "    num_assembler = VectorAssembler(inputCols=[n], outputCol= n + \"_vecotr\")\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol= n + \"_scaled\")\n",
    "    stages += [num_assembler, num_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9e35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_inputs = [c + \"_onehot\" for c in cat_feats] + [n + \"_scaled\" for n in num_feats]\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"feature_vector\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144a456",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4abb1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr = LinearRegression(\n",
    "    maxIter=30,\n",
    "    solver=\"normal\",\n",
    "    labelCol='total_amount',\n",
    "    featuresCol='feature_vector'\n",
    ")\n",
    "\n",
    "# crossvalidation을 위한 stage\n",
    "cv_stages = stages + [lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e243aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv pipeline 생성 \n",
    "cv_pipeline = Pipeline(stages=cv_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4401c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder()\\\n",
    "                .addGrid(lr.elasticNetParam, [0.1, 0.2, 0.3, 0.4, 0.5])\\\n",
    "                .addGrid(lr.regParam, [0.01, 0.02, 0.03, 0.04, 0.05])\\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3575a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = CrossValidator(estimator=cv_pipeline,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=RegressionEvaluator(labelCol=\"total_amount\"),\n",
    "                           numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68456da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/20 20:57:07 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/05/20 20:57:07 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/05/20 20:57:08 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/05/20 20:57:08 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv_model = cross_val.fit(toy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493a7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = cv_model.bestModel.stages[-1]._java_obj.getElasticNetParam()\n",
    "reg_param = cv_model.bestModel.stages[-1]._java_obj.getRegParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d509c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b44e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transform_stages = stages\n",
    "pipeline = Pipeline(stages=transform_stages)\n",
    "fitted_transformer = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d965a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrain_df = fitted_transformer.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "450a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = LinearRegression(\n",
    "    maxIter=50,\n",
    "    solver=\"normal\",\n",
    "    labelCol=\"total_amount\",\n",
    "    featuresCol=\"feature_vector\",\n",
    "    elasticNetParam=alpha,\n",
    "    regParam=reg_param,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4265a9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vecotr: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vecotr: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vecotr: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vtrain_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d00f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a95e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = fitted_transformer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05b3df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d0d5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[passenger_count: int, pickup_location_id: int, dropoff_location_id: int, trip_distance: double, pickup_time: int, day_of_week: string, total_amount: double, pickup_location_id_idx: double, pickup_location_id_onehot: vector, dropoff_location_id_idx: double, dropoff_location_id_onehot: vector, day_of_week_idx: double, day_of_week_onehot: vector, passenger_count_vecotr: vector, passenger_count_scaled: vector, trip_distance_vecotr: vector, trip_distance_scaled: vector, pickup_time_vecotr: vector, pickup_time_scaled: vector, feature_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a7f4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3046:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+\n",
      "|trip_distance|day_of_week|total_amount|        prediction|\n",
      "+-------------+-----------+------------+------------------+\n",
      "|          0.8|  Wednesday|         5.8|  7.69462101243899|\n",
      "|          4.8|  Wednesday|        28.5|24.010347213535233|\n",
      "|          2.1|    Tuesday|        15.8|15.583409150386142|\n",
      "|          3.5|    Tuesday|       22.45|19.468292024222382|\n",
      "|          6.1|     Monday|        26.3| 28.39942675137028|\n",
      "|          2.1|     Sunday|        14.8|13.946336976972514|\n",
      "|          0.4|    Tuesday|         5.8| 7.634021550500015|\n",
      "|          1.0|     Friday|         9.8| 9.203781746421113|\n",
      "|          1.3|   Saturday|         8.3| 9.174011850628828|\n",
      "|          2.2|    Tuesday|       15.95|13.403969441237292|\n",
      "|          5.2|     Monday|       26.15|23.890497962133416|\n",
      "|         12.4|   Saturday|        51.6|48.483750631227565|\n",
      "|          2.0|    Tuesday|       14.75|  13.4131209508338|\n",
      "|          4.1|     Monday|        22.8| 20.21692995099636|\n",
      "|          1.4|     Monday|        11.8|12.592694850062644|\n",
      "|          1.7|    Tuesday|        13.8| 14.16668378459822|\n",
      "|          2.3|    Tuesday|        13.8|15.902226399870298|\n",
      "|          0.7|    Tuesday|        9.95|10.551669569666979|\n",
      "|          3.9|   Saturday|       21.35|20.774813838309566|\n",
      "|          3.0|     Monday|       20.15|18.008803098931253|\n",
      "+-------------+-----------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.select([\"trip_distance\", \"day_of_week\", \"total_amount\", \"prediction\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f653ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.789833058355195"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02803459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895397549211991"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb8ab8",
   "metadata": {},
   "source": [
    "### model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbfba244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model_dir = \"/Users/yello-ow/taxi/spark/data/model\"\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b64ec6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dir = \"/Users/yello-ow/taxi/spark/data/pipeline\"\n",
    "pipeline.save(pipe_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10774483",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f15e53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8407cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegressionModel().load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5a1de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84595076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+------------------+\n",
      "|trip_distance|pickup_time|day_of_week|        prediction|\n",
      "+-------------+-----------+-----------+------------------+\n",
      "|          0.8|          8|  Wednesday|  7.69462101243899|\n",
      "|          4.8|          7|  Wednesday|24.010347213535233|\n",
      "|          2.1|         19|    Tuesday|15.583409150386142|\n",
      "|          3.5|          7|    Tuesday|19.468292024222382|\n",
      "|          6.1|         13|     Monday| 28.39942675137028|\n",
      "|          2.1|         11|     Sunday|13.946336976972514|\n",
      "|          0.4|         17|    Tuesday| 7.634021550500015|\n",
      "|          1.0|          8|     Friday| 9.203781746421113|\n",
      "|          1.3|         10|   Saturday| 9.174011850628828|\n",
      "|          2.2|         17|    Tuesday|13.403969441237292|\n",
      "|          5.2|          7|     Monday|23.890497962133416|\n",
      "|         12.4|         10|   Saturday|48.483750631227565|\n",
      "|          2.0|         10|    Tuesday|  13.4131209508338|\n",
      "|          4.1|         16|     Monday| 20.21692995099636|\n",
      "|          1.4|         14|     Monday|12.592694850062644|\n",
      "|          1.7|         13|    Tuesday| 14.16668378459822|\n",
      "|          2.3|         14|    Tuesday|15.902226399870298|\n",
      "|          0.7|         14|    Tuesday|10.551669569666979|\n",
      "|          3.9|         12|   Saturday|20.774813838309566|\n",
      "|          3.0|         14|     Monday|18.008803098931253|\n",
      "+-------------+-----------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(['trip_distance','pickup_time', 'day_of_week', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f0f5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
